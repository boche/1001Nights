{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    sys.argv = argv\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--log_dir', type = str, default = 'log', help = 'log dir')\n",
    "    parser.add_argument('--mode', type=str, required=True, choices=['train', 'test'], help = 'mode: train or test')\n",
    "    parser.add_argument('--input', type = str, help = 'input directory')\n",
    "    parser.add_argument('--ouput', type = str, help = 'output directory')\n",
    "    parser.add_argument('--epochs', type = int, default = 100, help = 'number of epochs')\n",
    "    parser.add_argument('--batch_size', type = int, default = 100, help = 'batch size')\n",
    "    parser.add_argument('--lr', type = float, default = 0.01, help = 'learning rate')\n",
    "    parser.add_argument('--saved_model', type = str, default = None, help = 'directory of saved model')\n",
    "    parser.add_argument('--cuda', action = 'store_true')\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    logging.basicConfig(level = 'DEBUG', format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    debug_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Debug by printing the passed arguments for the model \"\"\"\n",
    "def debug_args(flags):\n",
    "    logging.info('Parameters received:')\n",
    "    for arg in vars(flags):\n",
    "        value = getattr(flags, arg)\n",
    "        logging.info('* {} = {}'.format(arg, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autoEncDecoder(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.embedding = None\n",
    "        self.vocab_idx = None\n",
    "        self.word_cnt = None\n",
    "        self.params = None\n",
    "        \n",
    "        \n",
    "    def load_embed_vocab(self):\n",
    "        emb_dir = \"/data/ASR5/haomingc/1001Nights/emb2010.pkl\"\n",
    "        word_cnt_dir = \"/data/ASR5/haomingc/1001Nights/vocab2010.pkl\"\n",
    "        \n",
    "        self.embedding, self.vocab_idx = pickle.load(open(embed_dir, 'rb'))\n",
    "        print(type(self.embedding), self.embedding.shape)\n",
    "        \n",
    "        self.word_cnt = pickle.load(open(word_cnt_dir, 'rb'))\n",
    "        print(type(self.word_cnt), len(self.word_cnt))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import logging\n",
    "import pickle \n",
    "import random\n",
    "\n",
    "# from main import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim=500, n_layers=1, embedding_dim=300):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers)\n",
    "        \n",
    "    '''\n",
    "        @param input: list of indices\n",
    "        @param hidden: previous hidden state\n",
    "    '''\n",
    "    def forward(self, input, hidden_state):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = None\n",
    "        \n",
    "        for i in xrange(self.n_layers):\n",
    "            output, hidden_state = self.gru(output, hidden_state)\n",
    "        return output, hidden_state\n",
    "    \n",
    "    def init_hidden(self, use_cuda=False):\n",
    "        ret = Variable(torch.zeros(1, 1, self.hidden_dim))\n",
    "        print(ret)\n",
    "        return ret.cuda() if use_cuda else ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "#     main(sys.argv)\n",
    "\n",
    "#     logging.basicConfig(level='DEBUG', format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "#     model = autoEncDecoder()\n",
    "#     model.load_embed_vocab()\n",
    "    \n",
    "    encoder = Encoder(300)\n",
    "    encoder.init_hidden()\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
